{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify songs into different genres using Machine Learning\n",
    "After having an overview of the acoustic signal, their features and their feature extraction process, it is time to utilise our newly developed skill to work on a Machine Learning Problem.\n",
    "## Objective\n",
    "In his section, we will try to model a classifier to classify songs into different genres. Let us assume a scenario in which, for some reason, we find a bunch of randomly named MP3 files on our hard disk, which are assumed to contain music. Our task is to sort them according to the music genre into different folders such as jazz, classical, country, pop, rock, and metal.\n",
    "### Dataset\n",
    "We will be using the famous GITZAN dataset for our case study. This dataset was used for the well-known paper in genre classification “ Musical genre classification of audio signals “ by G. Tzanetakis and P. Cook in IEEE Transactions on Audio and Speech Processing 2002. The dataset consists of 1000 audio tracks each 30 seconds long. It contains 10 genres namely, blues, classical, country, disco, hiphop, jazz, reggae, rock, metal and pop. Each genre consists of 100 sound clips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music genre classification notebook\n",
    "## Importing Libraries\n",
    "**Source:** https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extractoring and preprocessing data\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image #PIL is the Python Imaging Library by Fredrik Lundh and Contributors.\n",
    "import pathlib\n",
    "# The pathlib module provides an object oriented approach to handling filesystem paths. \n",
    "# The module also provides functionality appropriate for various operating systems. Classes defined in this module are of \n",
    "# two types – pure path types and concrete path types. \n",
    "# While pure paths can only perform purely computational operations, concrete paths are capable of doing I/O operations too.\n",
    "# https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f\n",
    "working_dir = pathlib.PureWindowsPath('C:\\\\Users\\\\alvar\\\\Downloads\\\\genres')\n",
    "os.chdir(working_dir)\n",
    "\n",
    "import csv\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting music and features\n",
    "### Dataset\n",
    "We use GTZAN genre collection dataset for classification. \n",
    "\n",
    "The dataset consists of 10 genres i.e\n",
    "\n",
    "Blues\n",
    "Classical\n",
    "Country\n",
    "Disco\n",
    "Hiphop\n",
    "Jazz\n",
    "Metal\n",
    "Pop\n",
    "Reggae\n",
    "Rock\n",
    "Each genre contains 100 songs. Total dataset: 1000 songs\n",
    "\n",
    "### Extracting the Spectrogram for every Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)\n",
    "#     f-strings provide a way to embed expressions inside string literals, using a minimal syntax. \n",
    "#     It should be noted that an f-string is really an expression evaluated at run time, not a constant value. \n",
    "#     In Python source code, an f-string \n",
    "#     is a literal string, prefixed with 'f', \n",
    "#     which contains expressions inside braces. The expressions are replaced with their values.\n",
    "    for filename in os.listdir(f'./genres/{g}'):\n",
    "        songname = f'./genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf() #Clear the current figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the audio files get converted into their respective spectrograms .WE can now easily **extract features** from them.\n",
    "### Extracting features from Spectrogram\n",
    "We will extract:\n",
    "\n",
    "* Mel-frequency cepstral coefficients (MFCC)(20 in number)\n",
    "* Spectral Centroid,\n",
    "* Zero Crossing Rate\n",
    "* Chroma Frequencies\n",
    "* Spectral Roll-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "\n",
    "for i in range(1,21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data to csv file\n",
    "We write the data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "#genres = ['rock']\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./genres/{g}'):\n",
    "        songname = f'./genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rmse(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('data.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the Data in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>0.349943</td>\n",
       "      <td>0.130225</td>\n",
       "      <td>1784.420446</td>\n",
       "      <td>2002.650192</td>\n",
       "      <td>3806.485316</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>-113.596742</td>\n",
       "      <td>121.557302</td>\n",
       "      <td>-19.158825</td>\n",
       "      <td>...</td>\n",
       "      <td>8.810668</td>\n",
       "      <td>-3.667367</td>\n",
       "      <td>5.751690</td>\n",
       "      <td>-5.162761</td>\n",
       "      <td>0.750947</td>\n",
       "      <td>-1.691937</td>\n",
       "      <td>-0.409954</td>\n",
       "      <td>-2.300208</td>\n",
       "      <td>1.219928</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>0.340983</td>\n",
       "      <td>0.095918</td>\n",
       "      <td>1529.835316</td>\n",
       "      <td>2038.617579</td>\n",
       "      <td>3548.820207</td>\n",
       "      <td>0.056044</td>\n",
       "      <td>-207.556796</td>\n",
       "      <td>124.006717</td>\n",
       "      <td>8.930562</td>\n",
       "      <td>...</td>\n",
       "      <td>5.376802</td>\n",
       "      <td>-2.239119</td>\n",
       "      <td>4.216963</td>\n",
       "      <td>-6.012273</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>-0.716537</td>\n",
       "      <td>0.293875</td>\n",
       "      <td>-0.287431</td>\n",
       "      <td>0.531573</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>0.363603</td>\n",
       "      <td>0.175573</td>\n",
       "      <td>1552.481958</td>\n",
       "      <td>1747.165985</td>\n",
       "      <td>3040.514948</td>\n",
       "      <td>0.076301</td>\n",
       "      <td>-90.754394</td>\n",
       "      <td>140.459907</td>\n",
       "      <td>-29.109965</td>\n",
       "      <td>...</td>\n",
       "      <td>5.789265</td>\n",
       "      <td>-8.905224</td>\n",
       "      <td>-1.083720</td>\n",
       "      <td>-9.218359</td>\n",
       "      <td>2.455805</td>\n",
       "      <td>-7.726901</td>\n",
       "      <td>-1.815724</td>\n",
       "      <td>-3.433434</td>\n",
       "      <td>-2.226821</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>0.404779</td>\n",
       "      <td>0.141191</td>\n",
       "      <td>1070.119953</td>\n",
       "      <td>1596.333948</td>\n",
       "      <td>2185.028454</td>\n",
       "      <td>0.033309</td>\n",
       "      <td>-199.431144</td>\n",
       "      <td>150.099218</td>\n",
       "      <td>5.647594</td>\n",
       "      <td>...</td>\n",
       "      <td>6.087676</td>\n",
       "      <td>-2.476420</td>\n",
       "      <td>-1.073890</td>\n",
       "      <td>-2.874777</td>\n",
       "      <td>0.780976</td>\n",
       "      <td>-3.316932</td>\n",
       "      <td>0.637981</td>\n",
       "      <td>-0.619690</td>\n",
       "      <td>-3.408233</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>0.308590</td>\n",
       "      <td>0.091563</td>\n",
       "      <td>1835.494603</td>\n",
       "      <td>1748.362448</td>\n",
       "      <td>3580.945013</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>-160.266031</td>\n",
       "      <td>126.198800</td>\n",
       "      <td>-35.605448</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.806385</td>\n",
       "      <td>-6.934122</td>\n",
       "      <td>-7.558619</td>\n",
       "      <td>-9.173552</td>\n",
       "      <td>-4.512166</td>\n",
       "      <td>-5.453538</td>\n",
       "      <td>-0.924162</td>\n",
       "      <td>-4.409333</td>\n",
       "      <td>-11.703781</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  blues.00000.wav     0.349943  0.130225        1784.420446   \n",
       "1  blues.00001.wav     0.340983  0.095918        1529.835316   \n",
       "2  blues.00002.wav     0.363603  0.175573        1552.481958   \n",
       "3  blues.00003.wav     0.404779  0.141191        1070.119953   \n",
       "4  blues.00004.wav     0.308590  0.091563        1835.494603   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         2002.650192  3806.485316            0.083066 -113.596742   \n",
       "1         2038.617579  3548.820207            0.056044 -207.556796   \n",
       "2         1747.165985  3040.514948            0.076301  -90.754394   \n",
       "3         1596.333948  2185.028454            0.033309 -199.431144   \n",
       "4         1748.362448  3580.945013            0.101500 -160.266031   \n",
       "\n",
       "        mfcc2      mfcc3  ...      mfcc12    mfcc13    mfcc14    mfcc15  \\\n",
       "0  121.557302 -19.158825  ...    8.810668 -3.667367  5.751690 -5.162761   \n",
       "1  124.006717   8.930562  ...    5.376802 -2.239119  4.216963 -6.012273   \n",
       "2  140.459907 -29.109965  ...    5.789265 -8.905224 -1.083720 -9.218359   \n",
       "3  150.099218   5.647594  ...    6.087676 -2.476420 -1.073890 -2.874777   \n",
       "4  126.198800 -35.605448  ...   -2.806385 -6.934122 -7.558619 -9.173552   \n",
       "\n",
       "     mfcc16    mfcc17    mfcc18    mfcc19     mfcc20  label  \n",
       "0  0.750947 -1.691937 -0.409954 -2.300208   1.219928  blues  \n",
       "1  0.936109 -0.716537  0.293875 -0.287431   0.531573  blues  \n",
       "2  2.455805 -7.726901 -1.815724 -3.433434  -2.226821  blues  \n",
       "3  0.780976 -3.316932  0.637981 -0.619690  -3.408233  blues  \n",
       "4 -4.512166 -5.453538 -0.924162 -4.409333 -11.703781  blues  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35174862, -0.01072298, -0.58330334, ..., -0.23719158,\n",
       "         0.00761145,  0.60349813],\n",
       "       [-0.46146578, -0.53326615, -0.93906628, ..., -0.05518978,\n",
       "         0.5438236 ,  0.42403528],\n",
       "       [-0.18448399,  0.68001209, -0.90741936, ..., -0.60070707,\n",
       "        -0.29428464, -0.29511278],\n",
       "       ...,\n",
       "       [ 0.65431762, -0.75110651, -0.17418012, ...,  0.76028053,\n",
       "        -2.73474414, -0.26387449],\n",
       "       [-0.19983726, -0.71651358, -1.12235633, ...,  0.2717664 ,\n",
       "        -0.72311185, -0.64936228],\n",
       "       [-0.25070236, -1.16473892, -0.82782084, ..., -0.12506872,\n",
       "         0.08171799,  0.58748963]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing data into training and Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.53545232,  0.98658127,  0.45295673,  1.15213444,  0.62443893,\n",
       "       -0.00227625,  0.71007663, -0.06666625,  1.18949389, -2.21302668,\n",
       "        0.68231981, -0.82446666,  0.59165798, -1.49787199,  0.96551524,\n",
       "       -0.35347937,  0.02811474, -1.39848204,  0.77350933, -0.96373133,\n",
       "        0.76171841, -0.77148173,  1.0308406 ,  0.0454997 ,  1.14503488,\n",
       "        0.49551365])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with Keras\n",
    "#### Building our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 2.1661 - acc: 0.2500\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 44us/step - loss: 1.8157 - acc: 0.3725\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 37us/step - loss: 1.5809 - acc: 0.4050\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 32us/step - loss: 1.4230 - acc: 0.5012\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 37us/step - loss: 1.2859 - acc: 0.5625\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 34us/step - loss: 1.1820 - acc: 0.5975\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 36us/step - loss: 1.0912 - acc: 0.6525\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 30us/step - loss: 1.0140 - acc: 0.6700\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.9541 - acc: 0.7037\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.8976 - acc: 0.7137\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.8551 - acc: 0.7312\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.8012 - acc: 0.7475\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.7671 - acc: 0.7500\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.7465 - acc: 0.7662\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6988 - acc: 0.7737\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 34us/step - loss: 0.6840 - acc: 0.7700\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.6324 - acc: 0.8163\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.6049 - acc: 0.8100\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.5773 - acc: 0.8250\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.5605 - acc: 0.8313\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 272us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:  0.665\n"
     ]
    }
   ],
   "source": [
    "print('test_acc: ',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating our approach\n",
    "Let's set apart 200 samples in our training data to use as a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = X_train[:200]\n",
    "partial_x_train = X_train[200:]\n",
    "\n",
    "y_val = y_train[:200]\n",
    "partial_y_train = y_train[200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our network for 20 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 200 samples\n",
      "Epoch 1/30\n",
      "600/600 [==============================] - 1s 857us/step - loss: 2.2999 - acc: 0.1400 - val_loss: 2.1690 - val_acc: 0.2850\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 0s 73us/step - loss: 2.1257 - acc: 0.3750 - val_loss: 2.0492 - val_acc: 0.3150\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 0s 65us/step - loss: 1.9809 - acc: 0.3667 - val_loss: 1.9301 - val_acc: 0.3350\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 0s 58us/step - loss: 1.8376 - acc: 0.3800 - val_loss: 1.8167 - val_acc: 0.3700\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 0s 57us/step - loss: 1.7079 - acc: 0.4050 - val_loss: 1.7015 - val_acc: 0.3850\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 0s 105us/step - loss: 1.5848 - acc: 0.4583 - val_loss: 1.6010 - val_acc: 0.4250\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 0s 61us/step - loss: 1.4762 - acc: 0.5083 - val_loss: 1.5212 - val_acc: 0.4700\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 0s 68us/step - loss: 1.3783 - acc: 0.5583 - val_loss: 1.4569 - val_acc: 0.4950\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 0s 53us/step - loss: 1.2848 - acc: 0.5533 - val_loss: 1.4094 - val_acc: 0.4700\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 0s 66us/step - loss: 1.2034 - acc: 0.5633 - val_loss: 1.3547 - val_acc: 0.4750\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 0s 68us/step - loss: 1.1317 - acc: 0.6167 - val_loss: 1.3121 - val_acc: 0.5250\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 0s 65us/step - loss: 1.0779 - acc: 0.6583 - val_loss: 1.2613 - val_acc: 0.5500\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 0s 60us/step - loss: 1.0011 - acc: 0.6733 - val_loss: 1.2759 - val_acc: 0.4950\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.9779 - acc: 0.6550 - val_loss: 1.2716 - val_acc: 0.5050\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.9419 - acc: 0.6667 - val_loss: 1.2547 - val_acc: 0.5400\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.9145 - acc: 0.7083 - val_loss: 1.1984 - val_acc: 0.5250\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 0s 62us/step - loss: 0.8456 - acc: 0.7283 - val_loss: 1.2448 - val_acc: 0.5400\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 0s 70us/step - loss: 0.8498 - acc: 0.7217 - val_loss: 1.1778 - val_acc: 0.5600\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 0s 65us/step - loss: 0.8097 - acc: 0.7233 - val_loss: 1.1950 - val_acc: 0.5550\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.7953 - acc: 0.7317 - val_loss: 1.2038 - val_acc: 0.5350\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.7368 - acc: 0.7617 - val_loss: 1.2239 - val_acc: 0.5550\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 0s 68us/step - loss: 0.7262 - acc: 0.7533 - val_loss: 1.2060 - val_acc: 0.5350\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.7034 - acc: 0.7633 - val_loss: 1.1542 - val_acc: 0.5550\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 0s 57us/step - loss: 0.6621 - acc: 0.7983 - val_loss: 1.1668 - val_acc: 0.5500\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.6539 - acc: 0.7917 - val_loss: 1.1741 - val_acc: 0.5650\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 0s 63us/step - loss: 0.6165 - acc: 0.8167 - val_loss: 1.1916 - val_acc: 0.5300\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5938 - acc: 0.8217 - val_loss: 1.1916 - val_acc: 0.5550\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 0s 58us/step - loss: 0.5661 - acc: 0.8350 - val_loss: 1.1663 - val_acc: 0.5550\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 0s 81us/step - loss: 0.5321 - acc: 0.8533 - val_loss: 1.1664 - val_acc: 0.5600\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 0s 71us/step - loss: 0.5257 - acc: 0.8450 - val_loss: 1.1466 - val_acc: 0.5800\n",
      "200/200 [==============================] - 0s 75us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=30,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1210992336273193, 0.615]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999998"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Music Genre Classification is one of the many branches of Music Information Retrieval. From here you can perform other tasks on musical data like beat tracking, music generation, recommender systems, track separation and instrument recognition etc. Music analysis is a diverse field and also an interesting one. A music session somehow represents a moment for the user. Finding these moments and describing them is an interesting challenge in the field of Data Science."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
